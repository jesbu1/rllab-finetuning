# Training & playing the default goal task with Agent Learning Framework (Alf)
# python -m alf.bin.train --root_dir=~/tmp/alf_ppo --gin_file=goaltask_ppo_pioneer.gin --alsologtostderr
# python -m alf.bin.play --root_dir=~/tmp/alf_ppo --gin_file=goaltask_ppo_pioneer.gin --record_file=goaltask.mp4

# Training with other task, 'kickball' for example:
# python -m alf.bin.train --root_dir=~/tmp/alf_ppo --gin_file=goaltask_ppo_pioneer.gin --alsologtostderr --gin_param="PlayGround.tasks=[@KickingBallTask]"

# If you are not recording video and observation does not contain image, you can add 'DISPLAY=null' to skip camera rendering, which will speedup the simulation a lot:
# DISPLAY=null python -m alf.bin.train ...

include 'common_ppo.gin'

# environment config
create_environment.env_name="SocialBot-PlayGround-v0"
create_environment.num_parallel_environments=16

# algorithm config
actor/ActorDistributionNetwork.fc_layer_params=(128, 64)
actor/ActorDistributionNetwork.activation_fn=@tf.nn.tanh
actor/ActorDistributionNetwork.continuous_projection_net=@NormalProjectionNetwork
NormalProjectionNetwork.init_means_output_factor=1e-10
NormalProjectionNetwork.std_bias_initializer_value=0.0
value/ValueNetwork.fc_layer_params=(128, 64)
value/ValueNetwork.activation_fn=@tf.nn.tanh
ac/Adam.learning_rate=3e-4
PPOLoss.entropy_regularization=5e-3

# training config
TrainerConfig.mini_batch_length=1
TrainerConfig.unroll_length=1024
TrainerConfig.mini_batch_size=4096
TrainerConfig.eval_interval=100
TrainerConfig.checkpoint_interval=10
TFUniformReplayBuffer.max_length=1024

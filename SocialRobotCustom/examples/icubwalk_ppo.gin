# training & playing with Agent Learning Framework (Alf)
# python -m alf.bin.train --root_dir=~/tmp/icub_ppo --gin_file=icubwalk_sac.gin --alsologtostderr
# python -m alf.bin.play --root_dir=~/tmp/icub_ppo --gin_file=icubwalk_sac.gin

include 'common_ppo.gin'

# environment config
create_environment.env_name="SocialBot-ICubWalkPID-v0"
create_environment.num_parallel_environments=12

# algorithm config
actor/ActorDistributionNetwork.fc_layer_params=(256, 128)
actor/ActorDistributionNetwork.activation_fn=@tf.nn.tanh
actor/ActorDistributionNetwork.continuous_projection_net=@NormalProjectionNetwork
NormalProjectionNetwork.init_means_output_factor=1e-10
NormalProjectionNetwork.std_bias_initializer_value=0.0
value/ValueNetwork.fc_layer_params=(256, 128)
value/ValueNetwork.activation_fn=@tf.nn.tanh
ActorCriticAlgorithm.actor_network=@actor/ActorDistributionNetwork()
ActorCriticAlgorithm.value_network=@value/ValueNetwork()
PPOLoss.entropy_regularization=1e-3


# training config
TrainerConfig.mini_batch_length=1
TrainerConfig.mini_batch_size=4096
TrainerConfig.summary_interval=1
TrainerConfig.num_updates_per_train_step=20
TrainerConfig.eval_interval=100
